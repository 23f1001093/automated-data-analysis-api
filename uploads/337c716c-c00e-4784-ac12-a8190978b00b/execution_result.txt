
[2025-08-19 15:45:10]
âœ… requests already installed.
----------------------------------------

[2025-08-19 15:45:10]
ðŸ“¦ Installing beautifulsoup4 ...
----------------------------------------

[2025-08-19 15:45:11]
ðŸ“œ Executing Code:
import requests
from bs4 import BeautifulSoup

url = "https://en.wikipedia.org/wiki/List_of_highest-grossing_films"
response = requests.get(url)

if response.status_code == 200:
    soup = BeautifulSoup(response.content, "html.parser")
    table = soup.find("table", {"class": "wikitable"})

    if table:
        headers = [header.get_text(strip=True) for header in table.find_all("th")]
        rows = table.find_all("tr")[1:4]  # Get first 3 data rows

        summary = f'Successfully scraped the URL. Found a table with the caption "Highest-grossing films".\n'
        summary += f"Table Headers: {headers}\n\n"
        summary += "First 3 rows:\n"
        for row in rows:
            cols = [col.get_text(strip=True) for col in row.find_all("td")]
            summary += f"{cols}\n"

        with open(
            "uploads/337c716c-c00e-4784-ac12-a8190978b00b/metadata.txt", "a"
        ) as f:
            f.write(summary)
    else:
        with open(
            "uploads/337c716c-c00e-4784-ac12-a8190978b00b/metadata.txt", "a"
        ) as f:
            f.write("Could not find the wikitable on the page.\n")
else:
    with open("uploads/337c716c-c00e-4784-ac12-a8190978b00b/metadata.txt", "a") as f:
        f.write(
            f"Failed to retrieve the webpage. Status code: {response.status_code}\n"
        )

----------------------------------------

[2025-08-19 15:45:12]
âœ… Code executed successfully:

----------------------------------------

[2025-08-19 15:45:44]
âœ… pandas already installed.
----------------------------------------

[2025-08-19 15:45:44]
âœ… numpy already installed.
----------------------------------------

[2025-08-19 15:45:44]
âœ… matplotlib already installed.
----------------------------------------

[2025-08-19 15:45:44]
ðŸ“¦ Installing seaborn ...
----------------------------------------

[2025-08-19 15:45:44]
ðŸ“¦ Installing lxml ...
----------------------------------------

[2025-08-19 15:45:45]
ðŸ“œ Executing Code:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import io
import base64
import json
import re


def solve():
    url = "https://en.wikipedia.org/wiki/List_of_highest-grossing_films"
    # Use pandas to read the HTML table directly, matching the caption
    try:
        tables = pd.read_html(url, match="Highest-grossing films")
        df = tables[0]
    except ValueError:
        # Fallback if match fails, read all tables and infer
        tables = pd.read_html(url)
        df = tables[0]  # Assume it's the first one

    # Clean column names if they are multi-level
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = df.columns.droplevel(0)

    # Data Cleaning
    df["Worldwide gross"] = (
        df["Worldwide gross"].astype(str).apply(lambda x: re.sub(r"\D", "", x))
    )
    df["Worldwide gross"] = pd.to_numeric(df["Worldwide gross"], errors="coerce")
    df["Year"] = pd.to_numeric(df["Year"].astype(str).str[:4], errors="coerce")
    df["Rank"] = pd.to_numeric(df["Rank"], errors="coerce")
    df["Peak"] = pd.to_numeric(df["Peak"], errors="coerce")
    df.dropna(inplace=True)

    # Question 1: How many $2 bn movies were released before 2000?
    q1_answer = df[
        (df["Worldwide gross"] >= 2_000_000_000) & (df["Year"] < 2000)
    ].shape[0]

    # Question 2: Which is the earliest film that grossed over $1.5 bn?
    billion_1_5_df = df[df["Worldwide gross"] >= 1_500_000_000]
    q2_answer = billion_1_5_df.sort_values(by="Year", ascending=True).iloc[0]["Title"]

    # Question 3: What's the correlation between the Rank and Peak?
    q3_answer = df["Rank"].corr(df["Peak"])

    # Question 4: Draw a scatterplot of Rank and Peak
    plt.figure(figsize=(8, 6))
    sns.regplot(
        x="Rank",
        y="Peak",
        data=df,
        scatter_kws={"alpha": 0.6},
        line_kws={"color": "red", "linestyle": "--"},
    )
    plt.title("Rank vs. Peak of Highest-Grossing Films")
    plt.xlabel("Rank")
    plt.ylabel("Peak")
    plt.grid(True)

    # Save plot to a base64 string
    buf = io.BytesIO()
    plt.savefig(buf, format="png", bbox_inches="tight")
    buf.seek(0)
    img_base64 = base64.b64encode(buf.read()).decode("utf-8")
    q4_answer = f"data:image/png;base64,{img_base64}"
    plt.close()

    # Final answers array
    final_answers = [q1_answer, q2_answer, q3_answer, q4_answer]

    # Save to result.json
    with open("uploads/337c716c-c00e-4784-ac12-a8190978b00b/result.json", "w") as f:
        json.dump(final_answers, f)


solve()

----------------------------------------

[2025-08-19 15:45:48]
âœ… Code executed successfully:

----------------------------------------

[2025-08-19 15:45:58]
ðŸ“œ Executing Code:

----------------------------------------

[2025-08-19 15:45:59]
âœ… Code executed successfully:

----------------------------------------
